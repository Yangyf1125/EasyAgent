import os, operator, signal, logging,asyncio,threading,traceback,sys
from datetime import datetime
from langgraph.prebuilt import create_react_agent
from pydantic import BaseModel, Field
from typing import Annotated, List, Tuple,Union
from typing_extensions import TypedDict
from langchain_core.prompts import ChatPromptTemplate
from langgraph.graph import END,StateGraph, START
from dotenv import load_dotenv
from langchain_mcp_adapters.client import MultiServerMCPClient
import streamlit as st
os.environ["DEEPSEEK_API_KEY"] = "sk-2574248e129a44cbbb543c8ffcceeec8"
from prompt import REACT_PROMPT, REACT_PROMPT_CH, PLANNER_PROMPT, PLANNER_PROMPT_CH, REPLANNER_PROMPT
from langchain_deepseek import ChatDeepSeek
# è®¾ç½® Windows ä¸Šçš„äº‹ä»¶å¾ªç¯ç­–ç•¥
if sys.platform == 'win32':
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

class OutputLogger:
    def __init__(self, log_file='execution_log.txt'):
        self.log_file = log_file
        self._setup_logger()
        
    def _setup_logger(self):
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        self.logger = logging.getLogger('execution_logger')
        self.logger.setLevel(logging.INFO)
        
        # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨ï¼ŒæŒ‡å®šUTF-8ç¼–ç 
        file_handler = logging.FileHandler(self.log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # è®¾ç½®æ—¥å¿—æ ¼å¼
        formatter = logging.Formatter('%(asctime)s - %(message)s')
        file_handler.setFormatter(formatter)
        
        # æ·»åŠ å¤„ç†å™¨
        self.logger.addHandler(file_handler)
        
    def log(self, message):
        """è®°å½•æ—¥å¿—ä¿¡æ¯"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_message = f"{timestamp} - {message}"
        self.logger.info(log_message)
        print(log_message)  # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°

# åˆå§‹åŒ–å…¨å±€æ—¥å¿—è®°å½•å™¨
output_logger = OutputLogger()

# é…ç½®è¿æ¥æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    filename='mcp_connection.log'
)

# åŠ è½½ç¯å¢ƒå˜é‡
# load_dotenv()
# api_key = os.getenv("DEEPSEEK_API_KEY")


llm = ChatDeepSeek(model="deepseek-chat", base_url="https://api.deepseek.com",api_key="sk-2574248e129a44cbbb543c8ffcceeec8",temperature=0)
base_llm = ChatDeepSeek(model="deepseek-chat", base_url="https://api.deepseek.com", 
                       api_key="sk-2574248e129a44cbbb543c8ffcceeec8", temperature=0)
prompt = REACT_PROMPT

class PlanExecute(TypedDict):
    input: str
    plan: List[str]
    past_steps: Annotated[List[Tuple], operator.add]
    response: str

class Plan(BaseModel):
    """Plan to follow in future"""
    steps: List[str] = Field(
        description="different steps to follow, should be in sorted order"
    )

class Response(BaseModel):
    """Response to user."""
    response: str

class Act(BaseModel):
    """Action to perform."""
    action: Union[Response, Plan] = Field(
        description="Action to perform. If you want to respond to user, use Response. "
        "If you need to further use tools to get the answer, use Plan."
    )

def clear_previous_task():
    """
    æ¸…ç©ºä¸Šä¸€ä¸ªä»»åŠ¡çš„å†…å®¹
    ä¿ç•™ç”¨æˆ·è¾“å…¥æ¡†å’ŒåŸºæœ¬ç•Œé¢å…ƒç´ 
    """
    # è·å–å½“å‰æ¶ˆæ¯åˆ—è¡¨
    # if "messages" in st.session_state:
    #     # åªä¿ç•™ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    #     if len(st.session_state["messages"]) > 0:
    #         first_message = st.session_state["messages"][0]
    #         st.session_state["messages"] = [first_message]
    #     else:
    #         st.session_state["messages"] = []
    
    if "messages" in st.session_state:
        # åªä¿ç•™ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        if len(st.session_state["messages"]) > 0:
            st.session_state["messages"] = []

def add_clear_button():
    """
    æ·»åŠ ä¸€ä¸ªæ¸…ç©ºæŒ‰é’®åˆ°ç•Œé¢
    """
    if st.button("æ¸…ç©ºå†…å®¹", help="æ¸…ç©ºå½“å‰é¡µé¢å†…å®¹ï¼Œåˆ›å»ºæ–°ä»»åŠ¡"):
        clear_previous_task()
        st.rerun()  # é‡æ–°è¿è¡Œåº”ç”¨ä»¥æ›´æ–°ç•Œé¢

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(page_title="FengAgent Web Interface", layout="wide")

# è®¾ç½®æ ‡é¢˜
st.title("ğŸ¤– FengAgent æ™ºèƒ½ä½“")

# åˆå§‹åŒ–session state
if "messages" not in st.session_state:
    st.session_state["messages"] = []

    if threading.current_thread() is threading.main_thread():
        signal.signal(signal.SIGINT, handle_interrupt)
        signal.signal(signal.SIGTERM, handle_interrupt)

client = MultiServerMCPClient(
    {
        "math": {
            "command": "python",
            "args": ["D:/YangYufeng/zs/lang_learn/adapter/math_server.py"],
            "transport": "stdio",
        },
        "amap-amap-sse": {
            "url": "https://mcp.amap.com/sse?key=1253cf9b3968fc48fd39b06b02fa5211",
            "transport": "sse",
        },
        "tavily-mcp": {
            "command": "npx",
            "args": ["-y", "tavily-mcp"],
            "env": {"TAVILY_API_KEY": "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"},
            "autoApprove": []
        },
        "mcp-akshare": {
            "command": "uvx",
            "args": ["D:/Github/mcp-akshare"]
        },
    }
)
output_logger.log("MCPå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
tools = client.get_tools()
agent_executor = create_react_agent("deepseek:deepseek-chat", tools, prompt=prompt)

planner_prompt = ChatPromptTemplate.from_messages([
    ("system", PLANNER_PROMPT),
    ("placeholder", "{messages}"),
])
planner = planner_prompt | base_llm.with_structured_output(Plan)

replanner_prompt = ChatPromptTemplate.from_template(
    """For the given objective, analyze the current progress and generate the next actionable step. \
    Each step should be self-contained with all necessary context from previous results. \
    The final step should provide the complete answer to the original objective.

    If still need more steps,Generate the next step that:
        1. Builds upon the existing results
        2. Contains all necessary context from previous steps
        3. Is a single, clear and executable task
        4. Moves us closer to the final answer

    If no more steps are needed, respond with the final answer:
        First, summarize all completed steps and their results as a process summary.
        Then, give the final answer result to the user input

    please use Chinese.""" +
    """Current objective:
    {input}

    Original plan:
    {plan}

    Completed steps and their results:
    {past_steps}
    """
)
replanner = replanner_prompt | base_llm.with_structured_output(Act)

async def execute_step(state: PlanExecute):
    task = state["plan"][0]
    task_formatted = f"è¯·æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡:\n{task}"
    output_logger.log(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task}")
    agent_response = await agent_executor.ainvoke(
        {"messages": [("user", task_formatted)]}
    )
    result = agent_response["messages"][-1].content
    output_logger.log(f"ä»»åŠ¡å®Œæˆ: {task}\nç»“æœ: {result}")
    return {"past_steps": [(task, result)]}

async def plan_step(state: PlanExecute):
    output_logger.log(f"å¼€å§‹è§„åˆ’ä»»åŠ¡: {state['input']}")
    plan = await planner.ainvoke({"messages": [("user", state["input"])]})
    output_logger.log("è§„åˆ’å®Œæˆ:")
    for step in plan.steps:
        output_logger.log(f"- {step}")
    return {"plan": plan.steps}

async def replan_step(state: PlanExecute):
    output_logger.log("é‡æ–°è¯„ä¼°å½“å‰è¿›åº¦...")
    output = await replanner.ainvoke(state)
    if isinstance(output.action, Response):
        output_logger.log("ç”Ÿæˆæœ€ç»ˆå“åº”")
        return {"response": output.action.response}
    else:
        output_logger.log("ç”Ÿæˆæ–°çš„è®¡åˆ’:")
        for step in output.action.steps:
            output_logger.log(f"- {step}")
        return {"plan": output.action.steps}

def should_end(state: PlanExecute):
    if "response" in state and state["response"]:
        return END
    else:
        return "agent"

def pretty_print(event):
    if "planner" in event:
        st.session_state["messages"].append({"role": "assistant", "content": "ã€è§„åˆ’ä»»åŠ¡æ­¥éª¤ã€‘"})
        with st.chat_message("assistant"):
            st.markdown("ã€è§„åˆ’ä»»åŠ¡æ­¥éª¤ã€‘")
        for idx, step in enumerate(event["planner"]["plan"], 1):
            output_logger.log(f"{step}")
            st.session_state["messages"].append({"role": "assistant", "content": f"{step}"})
            st.markdown(f"{step}")
    if "agent" in event:
        output_logger.log("ã€æ‰§è¡Œç»“æœã€‘")
        st.session_state["messages"].append({"role": "assistant", "content": "ã€æ‰§è¡Œç»“æœã€‘"})
        with st.chat_message("assistant"):
            st.markdown("ã€æ‰§è¡Œç»“æœã€‘")
        for step, result in event["agent"]["past_steps"]:
            output_logger.log(f"æ­¥éª¤: {step}")
            output_logger.log(f"ç»“æœ: {result}")
            st.session_state["messages"].append({"role": "assistant", "content": f"æ­¥éª¤: {step}\nç»“æœ: {result}"})
            with st.chat_message("assistant"):
                st.markdown(f"æ­¥éª¤: {step}\nç»“æœ: {result}")
    if "replan" in event:
        if "plan" in event["replan"]:
            output_logger.log("ã€é‡æ–°è§„åˆ’ä»»åŠ¡ã€‘")
            st.session_state["messages"].append({"role": "assistant", "content": "ã€é‡æ–°è§„åˆ’ä»»åŠ¡ã€‘"})
            with st.chat_message("assistant"):
                st.markdown("ã€é‡æ–°è§„åˆ’ä»»åŠ¡ã€‘")
            for idx, step in enumerate(event["replan"]["plan"], 1):
                output_logger.log(f"{step}")    
                st.session_state["messages"].append({"role": "assistant", "content": f"{step}"})
                with st.chat_message("assistant"):
                    st.markdown(f"{step}")  
        if "response" in event["replan"]:
            output_logger.log("ã€æœ€ç»ˆç»“æœã€‘")
            st.session_state["messages"].append({"role": "assistant", "content": "ã€æœ€ç»ˆç»“æœã€‘"})
            with st.chat_message("assistant"):
                st.markdown("ã€æœ€ç»ˆç»“æœã€‘")
            output_logger.log(f"{event['replan']['response']}")
            st.session_state["messages"].append({"role": "assistant", "content": f"ã€æœ€ç»ˆç»“æœã€‘\n{event['replan']['response']}"})
            with st.chat_message("assistant"):
                st.markdown(f"ã€æœ€ç»ˆç»“æœã€‘\n{event['replan']['response']}")

# åˆ›å»ºä¸»å®¹å™¨
with st.container():
    st.header("ä¸ FengAgent å¯¹è¯")
    st.markdown("FengAgent æ˜¯ä¸€ä¸ªåŸºäºDeepseek LLMçš„Plan-executeæ¶æ„æ™ºèƒ½ä½“Agentï¼Œå…·æœ‰ç½‘é¡µæœç´¢ã€è‚¡ç¥¨æŸ¥è¯¢ä¸åˆ†æã€åœ°å›¾æŸ¥è¯¢ä¸å¯¼èˆªç­‰åŠŸèƒ½")
    st.markdown("Author: YYF <small>from CMS Fintech Centre</small>", unsafe_allow_html=True)

    # æ·»åŠ æ¸…ç©ºæŒ‰é’®
    add_clear_button()
    
    # æ˜¾ç¤ºå†å²æ¶ˆæ¯
    for message in st.session_state["messages"]:
        if message["role"] == "user":
            with st.chat_message("user"):
                st.markdown(message["content"])
        else:
            with st.chat_message("assistant"):
                st.markdown(message["content"])
    
    # ç”¨æˆ·è¾“å…¥
    prompt = st.chat_input("è¯·è¾“å…¥æ‚¨çš„ä»»åŠ¡...")
    
    if prompt:
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²è®°å½•
        st.session_state["messages"].append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # åˆ›å»ºçŠ¶æ€å¯¹è±¡
        state = PlanExecute(
            input=prompt,
            plan=[],
            past_steps=[],
            response=""
        )
        
        # ä½¿ç”¨ asyncio è¿è¡Œå¼‚æ­¥ä»»åŠ¡
        async def run_agent_async():
            workflow = StateGraph(PlanExecute)
            workflow.add_node("planner", plan_step)
            workflow.add_node("agent", execute_step)
            workflow.add_node("replan", replan_step)
            workflow.add_edge(START, "planner")
            workflow.add_edge("planner", "agent")
            workflow.add_edge("agent", "replan")
            workflow.add_conditional_edges("replan", should_end, ["agent", END])
            app = workflow.compile()
            
            config = {"recursion_limit": 50}
            inputs = {"input": prompt}
            
            with st.spinner("FengAgentæ­£åœ¨æ€è€ƒ..."):
                async for event in app.astream(inputs, config=config):
                    pretty_print(event)
        
        # åœ¨ Streamlit ä¸­è¿è¡Œå¼‚æ­¥ä»£ç 
        asyncio.run(run_agent_async())

# æ·»åŠ ä¾§è¾¹æ è¯´æ˜
with st.sidebar:
    st.header("ä½¿ç”¨è¯´æ˜")
    st.markdown("""
    1. åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥ä»»åŠ¡ï¼Œå¦‚â€œå¸®æˆ‘åˆ†ææ–°èƒ½æºé¢†åŸŸçš„è‚¡ç¥¨æƒ…å†µâ€
    2. FengAgentä¼šåˆ†ææ‚¨çš„é—®é¢˜å¹¶ä»»åŠ¡è§„åˆ’
    3. åœ¨ä¾æ¬¡æ‰§è¡Œå­ä»»åŠ¡çš„è¿‡ç¨‹ä¸­ï¼Œä¼šåŸºäºå½“å‰ä»»åŠ¡ç»“æœè¿›è¡Œé‡æ–°è§„åˆ’            
    3. æ‚¨å¯ä»¥æŸ¥çœ‹æ‰§è¡Œè¿‡ç¨‹å’Œæœ€ç»ˆç»“æœ
    4. æ‰€æœ‰å¯¹è¯å†å²éƒ½ä¼šè¢«ä¿å­˜
    5. ä½¿ç”¨"æ¸…ç©ºå†…å®¹"æŒ‰é’®å¯ä»¥æ¸…ç©ºå½“å‰é¡µé¢æ‰€æœ‰å†…å®¹
    """) 